{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1592d-7200-4e6e-97c2-7feb90fafdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook will load the model and test the result by first converting the headline to embedding, then testing the mebeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3d160",
   "metadata": {},
   "source": [
    "# Install required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3c5d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pylint in c:\\users\\bimal\\anaconda3\\lib\\site-packages (2.9.6)\n",
      "Requirement already satisfied: astroid<2.7,>=2.6.5 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from pylint) (2.6.6)\n",
      "Requirement already satisfied: isort<6,>=4.2.5 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from pylint) (5.9.3)\n",
      "Requirement already satisfied: mccabe<0.7,>=0.6 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from pylint) (0.6.1)\n",
      "Requirement already satisfied: toml>=0.7.1 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from pylint) (0.10.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from pylint) (0.4.6)\n",
      "Requirement already satisfied: lazy-object-proxy>=1.4.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from astroid<2.7,>=2.6.5->pylint) (1.6.0)\n",
      "Requirement already satisfied: wrapt<1.13,>=1.11 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from astroid<2.7,>=2.6.5->pylint) (1.12.1)\n",
      "Requirement already satisfied: setuptools>=20.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from astroid<2.7,>=2.6.5->pylint) (58.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pylint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "518522bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: black in c:\\users\\bimal\\anaconda3\\lib\\site-packages (19.10b0)\n",
      "Requirement already satisfied: click>=6.5 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from black) (8.1.8)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from black) (21.2.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from black) (1.4.4)\n",
      "Requirement already satisfied: toml>=0.9.4 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from black) (0.10.2)\n",
      "Requirement already satisfied: typed-ast>=1.4.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from black) (1.4.3)\n",
      "Requirement already satisfied: regex in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from black) (2021.8.3)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from black) (0.12.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from click>=6.5->black) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db33d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.8.0\n",
      "Uninstalling torch-2.8.0:\n",
      "  Successfully uninstalled torch-2.8.0\n",
      "Found existing installation: torchvision 0.14.1\n",
      "Uninstalling torchvision-0.14.1:\n",
      "  Successfully uninstalled torchvision-0.14.1\n",
      "Found existing installation: transformers 4.57.6\n",
      "Uninstalling transformers-4.57.6:\n",
      "  Successfully uninstalled transformers-4.57.6\n",
      "Found existing installation: sentence-transformers 5.1.2\n",
      "Uninstalling sentence-transformers-5.1.2:\n",
      "  Successfully uninstalled sentence-transformers-5.1.2\n",
      "Found existing installation: accelerate 1.10.1\n",
      "Uninstalling accelerate-1.10.1:\n",
      "  Successfully uninstalled accelerate-1.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Bimal\\anaconda3\\Lib\\site-packages\\~-rch'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "Force uninstall the conflicting libraries\n",
    "!pip uninstall -y torch torchvision torchaudio transformers sentence-transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be575c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.8.0%2Bcpu-cp39-cp39-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.23.0%2Bcpu-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.8.0%2Bcpu-cp39-cp39-win_amd64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading https://download.pytorch.org/whl/cpu/torch-2.8.0%2Bcpu-cp39-cp39-win_amd64.whl (619.3 MB)\n",
      "   -------------------------------------- 619.3/619.3 MB 969.0 kB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchvision-0.23.0%2Bcpu-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 1.6/1.6 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.8.0%2Bcpu-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 2.5/2.5 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.8.0+cpu torchaudio-2.8.0+cpu torchvision-0.23.0+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "peft 0.10.0 requires accelerate>=0.21.0, which is not installed.\n",
      "peft 0.10.0 requires transformers, which is not installed.\n",
      "fastai 2.7.11 requires torch<1.14,>=1.7, but you have torch 2.8.0+cpu which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\bimal\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: requests in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2023.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bimal\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Using cached transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
      "Using cached sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Using cached accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: accelerate, transformers, sentence-transformers\n",
      "Successfully installed accelerate-1.10.1 sentence-transformers-5.1.2 transformers-4.57.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Reinstall fresh compatible versions\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install transformers sentence-transformers accelerate joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368e6b5",
   "metadata": {},
   "source": [
    "# Check if SVM model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99cc442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bimal\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment fixed and model loaded!\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "#print(f\"PyTorch Version: {torch.__version__}\") # Should be >= 2.1\n",
    "\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"Environment fixed and model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4634473-5cd9-4227-8846-ea0e1a13a65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bimal\\anaconda3\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = joblib.load('svm.joblib')\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761ae498-dd76-4feb-b810-af61157758ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa82259d-83c3-46c6-b627-49d1c215efbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([model.encode(\"Everything is terrible\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0d58fa1-09a3-44a6-81eb-8a7f034a146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([model.encode(\"Biden Issues a ‘Full and Unconditional Pardon’ of His Son Hunter. After pledging not do so amid President-elect Trump’s attacks, President Biden ended Hunter Biden’s legal woes, including a guilty verdict in a gun case.\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc18d304",
   "metadata": {},
   "source": [
    "# Create Program for HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "984e0425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from D:\\Desktop\\UChicago\\Classes\\Winter 2026 Python for ML Engineering ADSP 32026\\HW1\\assignment1\\assignment\\headlines_nyt_2024-12-02.txt...\n",
      "Success! Results saved to: headline_scores_source_datefileproduced.txt\n"
     ]
    }
   ],
   "source": [
    "# 2. Define file paths\n",
    "input_filename = r\"D:\\Desktop\\UChicago\\Classes\\Winter 2026 Python for ML Engineering ADSP 32026\\HW1\\assignment1\\assignment\\headlines_nyt_2024-12-02.txt\"\n",
    "output_filename = \"headline_scores_source_datefileproduced.txt\"\n",
    "\n",
    "# 3. Process the headlines and generate output\n",
    "print(f\"Reading from {input_filename}...\")\n",
    "\n",
    "try:\n",
    "    with open(input_filename, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_filename, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        lines = infile.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            headline = line.strip()\n",
    "            \n",
    "            # Skip empty lines\n",
    "            if not headline:\n",
    "                continue\n",
    "            \n",
    "            # Generate embedding\n",
    "            embedding = model.encode(headline)\n",
    "            \n",
    "            # Predict sentiment (clf.predict expects a list or 2D array)\n",
    "            prediction = clf.predict([embedding])[0]\n",
    "            \n",
    "            # Write format: Output, Original Headline\n",
    "            outfile.write(f\"{prediction}, {headline}\\n\")\n",
    "            \n",
    "    print(f\"Success! Results saved to: {output_filename}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find '{input_filename}'. Make sure the text file is in the same folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db8c4762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the directory of the text file (e.g., D:/Desktop/.../headlines_nyt_2024-12-02.txt): D:\\Desktop\\UChicago\\Classes\\Winter 2026 Python for ML Engineering ADSP 32026\\HW1\\assignment1\\assignment\\headlines_nyt_2024-12-02.txt\n",
      "Enter the source of the headlines (e.g., new york times): new york times\n",
      "Reading from D:\\Desktop\\UChicago\\Classes\\Winter 2026 Python for ML Engineering ADSP 32026\\HW1\\assignment1\\assignment\\headlines_nyt_2024-12-02.txt...\n",
      "Success! Results saved to: headline_scores_new_york_times_2026_01_25.txt\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Ask for user inputs\n",
    "input_file_dir = input(\"Enter the directory of the text file (e.g., D:/Desktop/.../headlines_nyt_2024-12-02.txt): \")\n",
    "source = input(\"Enter the source of the headlines (e.g., new york times): \")\n",
    "\n",
    "# Replace spaces with underscores in the source name\n",
    "source_formatted = source.replace(\" \", \"_\")\n",
    "\n",
    "# Define output filename\n",
    "output_filename = f\"headline_scores_{source_formatted}_{today}.txt\"\n",
    "\n",
    "# Generate today's date in the specified format\n",
    "today = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "\n",
    "# Process the headlines and generate output\n",
    "print(f\"Reading from {input_file_dir}...\")\n",
    "\n",
    "try:\n",
    "    with open(input_file_dir, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_filename, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "        lines = infile.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            headline = line.strip()\n",
    "\n",
    "            # Skip empty lines\n",
    "            if not headline:\n",
    "                continue\n",
    "\n",
    "            # Generate embedding\n",
    "            embedding = model.encode(headline)\n",
    "\n",
    "            # Predict sentiment (clf.predict expects a list or 2D array)\n",
    "            prediction = clf.predict([embedding])[0]\n",
    "\n",
    "            # Write format: Output, Original Headline\n",
    "            outfile.write(f\"{prediction}, {headline}\\n\")\n",
    "\n",
    "    print(f\"Success! Results saved to: {output_filename}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find '{input_file_dir}'. Make sure the text file is in the specified directory.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7690e705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing headline_sentiment_local_folder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile headline_sentiment_local_folder.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Load the model and classifier\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "clf = joblib.load('svm.joblib')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Set up Argument Parser\n",
    "parser = argparse.ArgumentParser(description=\"Use news headlines to predict sentiment using a pre-trained SVM.\")\n",
    "\n",
    "# Add arguments\n",
    "parser.add_argument(\"Txt_file\", type=str, help=\"The full path to the text file with one headline per line. Be sure to put double apostrophe around the path.\")\n",
    "parser.add_argument(\"Source\", type=str, help=\"The source of the headlines (e.g., New York Times). Be sure to put double apostrophe around the source.\")\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Replace spaces with underscores in the source name\n",
    "source_formatted = args.Source.replace(\" \", \"_\")\n",
    "\n",
    "# Generate today's date in the specified format\n",
    "today = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "\n",
    "# Define output filename\n",
    "output_filename = f\"headline_scores_{source_formatted}_{today}.txt\"\n",
    "\n",
    "# Process the headlines and generate output\n",
    "print(f\"Reading from {args.Txt_file}...\")\n",
    "\n",
    "try:\n",
    "    with open(args.Txt_file, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_filename, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "        lines = infile.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            headline = line.strip()\n",
    "\n",
    "            # Skip empty lines\n",
    "            if not headline:\n",
    "                continue\n",
    "\n",
    "            # Generate embedding\n",
    "            embedding = model.encode(headline)\n",
    "\n",
    "            # Predict sentiment (clf.predict expects a list or 2D array)\n",
    "            prediction = clf.predict([embedding])[0]\n",
    "\n",
    "            # Write format: Output, Original Headline\n",
    "            outfile.write(f\"{prediction}, {headline}\\n\")\n",
    "\n",
    "    print(f\"Success! Results saved to: {output_filename}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find '{args.Txt_file}'. Make sure the text file is in the specified directory.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c7dbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Module headline_sentiment_local_folder\n",
      "headline_sentiment_local_folder.py:12:0: C0301: Line too long (112/100) (line-too-long)\n",
      "headline_sentiment_local_folder.py:15:0: C0301: Line too long (158/100) (line-too-long)\n",
      "headline_sentiment_local_folder.py:16:0: C0301: Line too long (151/100) (line-too-long)\n",
      "headline_sentiment_local_folder.py:58:0: C0301: Line too long (109/100) (line-too-long)\n",
      "headline_sentiment_local_folder.py:1:0: C0114: Missing module docstring (missing-module-docstring)\n",
      "headline_sentiment_local_folder.py:9:0: C0413: Import \"from datetime import datetime\" should be placed at the top of the module (wrong-import-position)\n",
      "headline_sentiment_local_folder.py:60:7: W0703: Catching too general exception Exception (broad-except)\n",
      "headline_sentiment_local_folder.py:47:12: C0103: Constant name \"embedding\" doesn't conform to UPPER_CASE naming style (invalid-name)\n",
      "headline_sentiment_local_folder.py:9:0: C0411: standard import \"from datetime import datetime\" should be placed before \"import joblib\" (wrong-import-order)\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Your code has been rated at 6.90/10\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pylint headline_sentiment_local_folder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c147545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting headline_sentiment_local_folder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile headline_sentiment_local_folder.py\n",
    "\"\"\"\n",
    "This module processes a text file of headlines and predicts their sentiment\n",
    "(Optimistic, Pessimistic, Neutral) using a pre-trained SVM model.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to parse arguments, load models, and process headlines.\n",
    "    \"\"\"\n",
    "    # 1. Set up Argument Parser\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Use news headlines to predict sentiment using a pre-trained SVM.\"\n",
    "    )\n",
    "\n",
    "    # Add arguments (Strings split to satisfy line length limits)\n",
    "    parser.add_argument(\n",
    "        \"Txt_file\",\n",
    "        type=str,\n",
    "        help=(\"The full path to the text file with one headline per line. \"\n",
    "              \"Be sure to put double apostrophe around the path.\")\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"Source\",\n",
    "        type=str,\n",
    "        help=(\"The source of the headlines (e.g., New York Times). \"\n",
    "              \"Be sure to put double apostrophe around the source.\")\n",
    "    )\n",
    "\n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load the model and classifier\n",
    "    print(\"Loading models...\")\n",
    "    try:\n",
    "        model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        clf = joblib.load('svm.joblib')\n",
    "    except OSError as err:\n",
    "        print(f\"Error loading models (svm.joblib might be missing): {err}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Replace spaces with underscores in the source name\n",
    "    source_formatted = args.Source.replace(\" \", \"_\")\n",
    "\n",
    "    # Generate today's date in the specified format\n",
    "    today = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "\n",
    "    # Define output filename\n",
    "    output_filename = f\"headline_scores_{source_formatted}_{today}.txt\"\n",
    "\n",
    "    # Process the headlines and generate output\n",
    "    print(f\"Reading from {args.Txt_file}...\")\n",
    "\n",
    "    try:\n",
    "        with open(args.Txt_file, 'r', encoding='utf-8') as infile, \\\n",
    "             open(output_filename, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "            lines = infile.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                headline = line.strip()\n",
    "\n",
    "                # Skip empty lines\n",
    "                if not headline:\n",
    "                    continue\n",
    "\n",
    "                # Generate embedding\n",
    "                embedding = model.encode(headline)\n",
    "\n",
    "                # Predict sentiment (clf.predict expects a list or 2D array)\n",
    "                prediction = clf.predict([embedding])[0]\n",
    "\n",
    "                # Write format: Output, Original Headline\n",
    "                outfile.write(f\"{prediction}, {headline}\\n\")\n",
    "\n",
    "        print(f\"Success! Results saved to: {output_filename}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find '{args.Txt_file}'. \"\n",
    "              \"Make sure the text file is in the specified directory.\")\n",
    "\n",
    "    # pylint: disable=broad-except\n",
    "    except Exception as error:\n",
    "        print(f\"An unexpected error occurred: {error}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e9492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Module headline_sentiment_local_folder\n",
      "headline_sentiment_local_folder.py:12:0: R0914: Too many local variables (16/15) (too-many-locals)\n",
      "headline_sentiment_local_folder.py:88:11: W0703: Catching too general exception Exception (broad-except)\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Your code has been rated at 9.47/10 (previous run: 6.90/10, +2.58)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pylint headline_sentiment_local_folder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ecc998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_headline_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_headline_sentiment.py\n",
    "\"\"\"\n",
    "This module processes a text file of headlines and predicts their sentiment\n",
    "(Optimistic, Pessimistic, Neutral) using a pre-trained SVM model.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def parse_arguments():\n",
    "    \"\"\"\n",
    "    Sets up argument parsing and returns the parsed arguments.\n",
    "    Separating this reduces the local variable count in main().\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Use news headlines to predict sentiment using a pre-trained SVM.\"\n",
    "    )\n",
    "\n",
    "    # Add arguments (Strings split to satisfy line length limits)\n",
    "    parser.add_argument(\n",
    "        \"Txt_file\",\n",
    "        type=str,\n",
    "        help=(\"The full path to the text file with one headline per line. \"\n",
    "              \"Be sure to put double apostrophe around the path.\")\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"Source\",\n",
    "        type=str,\n",
    "        help=(\"The source of the headlines (e.g., New York Times). \"\n",
    "              \"Be sure to put double apostrophe around the source.\")\n",
    "    )\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load models and process headlines.\n",
    "    \"\"\"\n",
    "    # 1. Get Arguments\n",
    "    args = parse_arguments()\n",
    "\n",
    "    # 2. Load the model and classifier\n",
    "    print(\"Loading models...\")\n",
    "    try:\n",
    "        model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        clf = joblib.load('svm.joblib')\n",
    "    except OSError as err:\n",
    "        print(f\"Error loading models (svm.joblib might be missing): {err}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 3. Setup Filenames\n",
    "    source_formatted = args.Source.replace(\" \", \"_\")\n",
    "    today = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "    output_filename = f\"headline_scores_{source_formatted}_{today}.txt\"\n",
    "\n",
    "    print(f\"Reading from {args.Txt_file}...\")\n",
    "\n",
    "    # 4. Process the headlines\n",
    "    try:\n",
    "        with open(args.Txt_file, 'r', encoding='utf-8') as infile, \\\n",
    "             open(output_filename, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "            lines = infile.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                headline = line.strip()\n",
    "\n",
    "                # Skip empty lines\n",
    "                if not headline:\n",
    "                    continue\n",
    "\n",
    "                # Generate embedding\n",
    "                embedding = model.encode(headline)\n",
    "\n",
    "                # Predict sentiment\n",
    "                prediction = clf.predict([embedding])[0]\n",
    "\n",
    "                # Write format: Output, Original Headline\n",
    "                outfile.write(f\"{prediction}, {headline}\\n\")\n",
    "\n",
    "        print(f\"Success! Results saved to: {output_filename}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find '{args.Txt_file}'. \"\n",
    "              \"Make sure the text file is in the specified directory.\")\n",
    "\n",
    "    except Exception as error:  # pylint: disable=broad-except\n",
    "        print(f\"An unexpected error occurred: {error}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d7dcf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Your code has been rated at 10.00/10 (previous run: 9.47/10, +0.53)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pylint predict_headline_sentiment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b31cba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: headline_sentiment_local_folder.py [-h] Txt_file Source\n",
      "\n",
      "Use news headlines to predict sentiment using a pre-trained SVM.\n",
      "\n",
      "positional arguments:\n",
      "  Txt_file    The full path to the text file with one headline per line. Be sure to put double apostrophe around the\n",
      "              path.\n",
      "  Source      The source of the headlines (e.g., New York Times). Be sure to put double apostrophe around the source.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help  show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "%run headline_sentiment_local_folder.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6cb0a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: headline_sentiment_local_folder.py [-h] Txt_file Source\n",
      "headline_sentiment_local_folder.py: error: the following arguments are required: Txt_file, Source\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%run headline_sentiment_local_folder.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91819d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bimal\\anaconda3\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from D:\\Desktop\\UChicago\\Classes\\Winter 2026 Python for ML Engineering ADSP 32026\\HW1\\assignment1\\assignment\\headlines_nyt_2024-12-02.txt...\n",
      "Success! Results saved to: headline_scores_chicago_tribune_2026_01_25.txt\n"
     ]
    }
   ],
   "source": [
    "%run program7.py \"D:\\Desktop\\UChicago\\Classes\\Winter 2026 Python for ML Engineering ADSP 32026\\HW1\\assignment1\\assignment\\headlines_nyt_2024-12-02.txt\" \"chicago tribune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65018741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bimal\\anaconda3\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from D:\\Desktop\\UChicago\\Classes\\Winter 2026 Python for ML Engineering ADSP 32026\\HW1\\assignment1\\assignment\\headlines_chicagotribune_2024-12-01.txt...\n",
      "Success! Results saved to: headline_scores_chicago_tribune_2026_01_25.txt\n"
     ]
    }
   ],
   "source": [
    "%run headline_sentiment_local_folder.py -- \"D:\\Desktop\\UChicago\\Classes\\Winter 2026 Python for ML Engineering ADSP 32026\\HW1\\assignment1\\assignment\\headlines_chicagotribune_2024-12-01.txt\" \"chicago tribune\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
